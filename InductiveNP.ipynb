{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254b01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Uni\\Master Scriptie\\Code Snippets\\entity-deduplication-hack-main\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import numpy as np\n",
    "import torch\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models.inductive import InductiveNodePieceGNN\n",
    "from pykeen.losses import NSSALoss\n",
    "from torch.optim import Adam\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "import torch.nn.functional as F\n",
    "from modular_methods.similarity_utils import compute_cosine_similarity, match_entities\n",
    "from modular_methods.graphToText_utils import get_literals_for_entities\n",
    "from modular_methods.dedup_pipeline import deduplicate_graphs, save_matches\n",
    "from modular_methods.output_utils import build_final_result\n",
    "\n",
    "### ---- 1. Load RDF graphs ----\n",
    "\n",
    "main_graph = rdflib.Graph()\n",
    "train_graph = rdflib.Graph()\n",
    "test_graph = rdflib.Graph()\n",
    "\n",
    "main_graph.parse(\"data/healthcare_graph_Main.ttl\")\n",
    "train_graph.parse(\"data/healthcare_graph_train.ttl\")\n",
    "test_graph.parse(\"data/healthcare_graph_replaced_high.ttl\")\n",
    "\n",
    "# Combine for inductive training/testing\n",
    "train_combined = main_graph + train_graph\n",
    "test_combined = main_graph + test_graph\n",
    "\n",
    "### ---- 2. Convert graphs to triples arrays ----\n",
    "\n",
    "def graph_to_triples(g):\n",
    "    return [\n",
    "        (str(s), str(p), str(o))\n",
    "        for s, p, o in g\n",
    "        if not isinstance(s, rdflib.BNode) and not isinstance(o, rdflib.BNode)\n",
    "    ]\n",
    "\n",
    "train_triples = np.array(graph_to_triples(train_combined))\n",
    "test_triples = np.array(graph_to_triples(test_combined))\n",
    "main_triples = np.array(graph_to_triples(main_graph))\n",
    "test_only_triples = np.array(graph_to_triples(test_graph))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da323853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['http://example.org/Address/a56a9b25-ce34-4d81-916f-d21a06718ae8',\n",
       "        'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
       "        'https://schema.org/PostalAddress'],\n",
       "       ['http://example.org/Person/6840360b-c90e-4fc6-a125-631972492165',\n",
       "        'https://schema.org/gender', 'Female'],\n",
       "       ['http://example.org/Person/920c77b9-dee4-4982-afee-6f105951d86b',\n",
       "        'https://schema.org/identifier',\n",
       "        '920c77b9-dee4-4982-afee-6f105951d86b'],\n",
       "       ...,\n",
       "       ['http://example.org/Person/521d283f-6231-4268-bec9-22c004fcebd3',\n",
       "        'https://schema.org/worksFor',\n",
       "        'http://example.org/HealthcareOrganization/06d2ed7c-e6ac-4d8a-8160-ff927c7550f2'],\n",
       "       ['http://example.org/Person/d9cc401f-0767-4c9c-8bfc-cac98a0b5f8c',\n",
       "        'https://schema.org/email', 'michelecook@healthcare.org'],\n",
       "       ['http://example.org/Person/5f6ce363-6b90-4633-88a5-74df67e4598f',\n",
       "        'https://schema.org/gender', 'Female']], dtype='<U78')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563f4a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['http://example.org/Person/7f3f3a7a-d2b0-4249-a813-3fac30edc402',\n",
       "        'https://schema.org/jobTitle', 'Pulmonary Function Technologist'],\n",
       "       ['http://example.org/Person/a7a1f3fd-23ed-46c9-b8e9-c63fa15aec4e',\n",
       "        'https://schema.org/knowsLanguage', 'et'],\n",
       "       ['http://example.org/Person/cd66e089-73cf-46b8-8eae-cd5ab2ef2b41',\n",
       "        'https://schema.org/email', 'derickflemingphd@healthcare.org'],\n",
       "       ...,\n",
       "       ['http://example.org/ContactPoint/6b5bc344-01bb-47e2-bf69-cd8fa4b4da1c',\n",
       "        'https://schema.org/availableLanguage', \"['et', 'en']\"],\n",
       "       ['http://example.org/Person/1797ce99-3847-4bac-8acd-bea381b8190d',\n",
       "        'https://schema.org/gender', 'Male'],\n",
       "       ['http://example.org/Person/5f6ce363-6b90-4633-88a5-74df67e4598f',\n",
       "        'https://schema.org/gender', 'Female']], dtype='<U78')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8dd035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations in train: 21\n",
      "Number of relations in test: 21\n",
      "Number of common relations: 21\n",
      "Relations only in train: set()\n",
      "Relations only in test: set()\n"
     ]
    }
   ],
   "source": [
    "# Extract unique relations from train and test triples\n",
    "train_relations = set(train_triples[:, 1])\n",
    "test_relations = set(test_triples[:, 1])\n",
    "\n",
    "# Find common and unique relations\n",
    "common_relations = train_relations & test_relations\n",
    "train_only_relations = train_relations - test_relations\n",
    "test_only_relations = test_relations - train_relations\n",
    "\n",
    "print(f\"Number of relations in train: {len(train_relations)}\")\n",
    "print(f\"Number of relations in test: {len(test_relations)}\")\n",
    "print(f\"Number of common relations: {len(common_relations)}\")\n",
    "print(f\"Relations only in train: {train_only_relations}\")\n",
    "print(f\"Relations only in test: {test_only_relations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6e593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriplesFactory(num_entities=17517, num_relations=42, create_inverse_triples=True, num_triples=36755)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train = TriplesFactory.from_labeled_triples(train_triples, create_inverse_triples=True)\n",
    "tf_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ce470",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- 3. Build TriplesFactory objects ----\n",
    "\n",
    "tf_train = TriplesFactory.from_labeled_triples(train_triples, create_inverse_triples=True)\n",
    "tf_test = TriplesFactory.from_labeled_triples(\n",
    "    test_triples,\n",
    "    relation_to_id=tf_train.relation_to_id,\n",
    "    create_inverse_triples=True\n",
    ")\n",
    "tf_main = TriplesFactory.from_labeled_triples(\n",
    "    main_triples,\n",
    "    relation_to_id=tf_train.relation_to_id,\n",
    "    create_inverse_triples=True\n",
    ")\n",
    "tf_test_only = TriplesFactory.from_labeled_triples(\n",
    "    test_only_triples,\n",
    "    relation_to_id=tf_train.relation_to_id,\n",
    "    create_inverse_triples=True\n",
    ")\n",
    "\n",
    "### ---- 4. Train InductiveNodePieceGNN ----\n",
    "\n",
    "model = InductiveNodePieceGNN(\n",
    "    triples_factory=tf_train,\n",
    "    inference_factory=tf_test,\n",
    "    num_tokens=12,\n",
    "    aggregation=\"mlp\",\n",
    "    embedding_dim=128,\n",
    "    interaction=\"DistMult\",\n",
    "    loss=NSSALoss(margin=15),\n",
    "    random_seed=42,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "training_loop = SLCWATrainingLoop(\n",
    "    triples_factory=tf_train,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    mode=\"training\"\n",
    ")\n",
    "\n",
    "print(\"Training NodePiece...\")\n",
    "training_loop.train(tf_train, num_epochs=10)\n",
    "\n",
    "### ---- 5. Extract entity embeddings ----\n",
    "\n",
    "def extract_embeddings(model, triples_factory, mode=\"training\"):\n",
    "    model.mode = mode\n",
    "    emb_array = model.entity_representations[0]().detach().cpu().numpy()\n",
    "    entities = list(triples_factory.entity_to_id.keys())\n",
    "    return {e: emb_array[i] for i, e in enumerate(entities)}\n",
    "\n",
    "main_embeddings = extract_embeddings(model, tf_main, mode=\"training\")\n",
    "test_embeddings = extract_embeddings(model, tf_test_only, mode=\"testing\")\n",
    "\n",
    "# Make sure only common entities/types are compared (as your pipeline does)\n",
    "entity_ids1 = list(main_embeddings.keys())\n",
    "entity_ids2 = list(test_embeddings.keys())\n",
    "\n",
    "emb1 = torch.tensor([main_embeddings[e] for e in entity_ids1])\n",
    "emb2 = torch.tensor([test_embeddings[e] for e in entity_ids2])\n",
    "\n",
    "emb1 = F.normalize(emb1, p=2, dim=1)\n",
    "emb2 = F.normalize(emb2, p=2, dim=1)\n",
    "\n",
    "sim_matrix = compute_cosine_similarity(emb1, emb2)\n",
    "matches = match_entities(sim_matrix, entity_ids1, entity_ids2, threshold=0.7, top_k=5)\n",
    "\n",
    "# Literal-based filtering (as in your pipeline)\n",
    "literals1 = get_literals_for_entities(main_graph, entity_ids1)\n",
    "literals2 = get_literals_for_entities(test_graph, entity_ids2)\n",
    "from modular_methods.similarity_utils import Levenshtein_filter\n",
    "filtered_matches = Levenshtein_filter(matches, literals1, literals2, filter=True)\n",
    "\n",
    "### ---- 7. Format and save results ----\n",
    "\n",
    "final_result = build_final_result(\n",
    "    filtered_matches,\n",
    "    main_graph,\n",
    "    test_graph,\n",
    "    graph1_name=\"MainGraph\",\n",
    "    graph2_name=\"TestGraph\"\n",
    ")\n",
    "save_matches(final_result, \"NodePiece_dedup_results.json\")\n",
    "print(f\"Saved results to NodePiece_dedup_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
